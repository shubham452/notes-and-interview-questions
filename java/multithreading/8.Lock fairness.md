

Here are notes on locks' fairness, prevention of deadlocks, and code optimization, including coding examples as described in the sources:

### **Understanding Locks and Fairness**

A **lock** is used in multithreading to control access to a shared resource, ensuring that only one thread can access it at a time. **Fairness** in the context of locking refers to the order in which waiting threads acquire the lock. It ensures that the thread that has been waiting the longest (first-in-first-out or FIFO principle) gets the lock next. Without fairness, the order of lock acquisition can be arbitrary.

### **1. Unfair Locks (Default Behavior)**

By default, many locks, including the simple `Lock` example discussed, are **unfair**. This means that when multiple threads contend for a lock, there is no guaranteed order for which thread will acquire it next. The acquisition happens in an **arbitrary manner**.

**Coding Example: Unfair Lock**

```java
// Create an unfair lock (e.g., using ReentrantLock() without specifying fairness)
Lock unfairLock = new ReentrantLock(); // Source implicitly uses this concept even if not explicit in initial example

// Method to access a shared resource
public void accessResource() {
    unfairLock.lock(); // Acquire the lock
    try {
        System.out.println(Thread.currentThread().getName() + " acquired the lock"); // Print acquisition
        // Simulate some work
        Thread.sleep(1000); //
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt(); // Handle interruption
    } finally {
        unfairLock.unlock(); // Release the lock
        System.out.println(Thread.currentThread().getName() + " released the lock"); // Print release
    }
}

// In main method, multiple threads call accessResource()
// Example execution output (arbitrary order):
// One acquired the lock
// One released the lock
// Three acquired the lock
// Three released the lock
// Two acquired the lock
// Two released the lock
//
```
The observed output from running multiple threads that call `accessResource()` with an unfair lock can show an unpredictable order, such as `Thread One`, then `Thread Three`, then `Thread Two`, even if they were started in a different sequence. This demonstrates the **arbitrary nature** of unfair lock acquisition.

### **2. Fair Locks**

To make a lock **fair**, you explicitly configure it to follow a first-in-first-out (FIFO) policy. The `ReentrantLock` class provides this functionality.

**Coding Example: Fair Lock**

```java
// Create a fair lock using ReentrantLock with fairness set to true
Lock fairLock = new ReentrantLock(true); // Setting 'true' makes it a fair lock

// The accessResource() method would be similar to the unfair example,
// but now using 'fairLock' instead of 'unfairLock'.
public void accessResource() {
    fairLock.lock(); // Acquire the lock
    try {
        System.out.println(Thread.currentThread().getName() + " acquired the lock");
        Thread.sleep(1000);
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    } finally {
        fairLock.unlock();
        System.out.println(Thread.currentThread().getName() + " released the lock");
    }
}
// Now, regardless of how many times you run it, if requests happen in a specific order,
// the acquisition will follow that order (e.g., One, Two, Three).
```

**Demonstrating Consistent Request Order for Fair Locks**

While fair locks guarantee acquisition order based on request order, the order in which threads *request* the lock can still depend on the operating system's thread scheduling. To *demonstrate* a specific request order (e.g., ensuring thread 1 requests before thread 2), you can introduce `Thread.sleep()` delays in the main thread between starting each worker thread.

**Coding Example: Enforcing Request Order for Demonstration**

```java
// In main method:
Thread thread1 = new Thread(runnableObject, "Thread One");
Thread thread2 = new Thread(runnableObject, "Thread Two");
Thread thread3 = new Thread(runnableObject, "Thread Three");

thread1.start();
try {
    Thread.sleep(50); // Pause main thread for 50 milliseconds
} catch (InterruptedException e) {
    // Handle exception
}

thread2.start();
try {
    Thread.sleep(50); // Pause main thread for 50 milliseconds
} catch (InterruptedException e) {
    // Handle exception
}

thread3.start();

// With these sleeps, Thread One will request the lock, then Thread Two, then Thread Three.
// Since the lock is fair, the print output will consistently be:
// Thread One acquired the lock
// Thread One released the lock
// Thread Two acquired the lock
// Thread Two released the lock
// Thread Three acquired the lock
// Thread Three released the lock
//
```
This technique is primarily for **demonstration purposes** to ensure a specific order of requests for a fair lock.

### **3. Benefits of Fair Locks and Preventing Starvation**

One of the significant advantages of fair locks is the prevention of **starvation**. Starvation occurs when a thread is repeatedly denied access to a shared resource, even though it's ready to run, because other threads continually acquire the resource.

*   With fair locks, every thread waiting for the lock will **eventually get its turn** because of the FIFO ordering.
*   It ensures that **no thread is left out** or indefinitely delayed, similar to a queue where everyone gets a turn.

### **4. Disadvantages of `synchronized` and Advantages of Manual Locks**

The sources highlight several disadvantages of using the `synchronized` keyword compared to manual locking mechanisms like `ReentrantLock`:

*   **No Fairness Guarantee**: `synchronized` blocks do not guarantee fairness. The order of thread execution is arbitrary, which can lead to starvation.
*   **Indefinite Blocking**: If a thread is blocked waiting for a `synchronized` lock, it will remain blocked indefinitely until the lock is released. There's no mechanism to interrupt it while it's waiting for the lock.
*   **Not Interruptible**: A thread waiting to acquire a `synchronized` lock **cannot be interrupted** while it's in the waiting state.
*   **Cannot Differentiate Read/Write Operations**: `synchronized` treats all critical sections equally. It cannot distinguish between read operations (which could potentially be concurrent) and write operations (which require exclusive access). Consequently, it will **block all other threads** for both read and write operations, even if concurrent reads would be safe.

**Manual locks (like `ReentrantLock`) overcome these disadvantages**:

*   They **provide fairness** when configured as `new ReentrantLock(true)`.
*   They allow for **interruptible waiting**, meaning a thread waiting for a lock can be interrupted and gracefully exit its waiting state.
*   They can be used to **differentiate read and write operations** by using two separate locks (one for reads, one for writes), which is a crucial advantage for optimizing performance in read-heavy scenarios.
